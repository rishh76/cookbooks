{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "t87qbM5XvQHR",
        "D34rHojRHpi4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SDXL Dreambooth Finetuning with MonsterTuner API\n",
        "\n",
        "MonsterTuner is a no-code LLM finetuner for up to 10X more efficient and cost-effective finetuning of AI models for your business use-cases.\n",
        "\n",
        "#### Supported Models for Finetuning:\n",
        "\n",
        "1. LLM (Large Language Model) - For use-cases like chat completion, summary generation, sentiment analysis etc.\n",
        "2. Whisper - For speech to text transcription improvement.\n",
        "3. SDXL Dreambooth - Fine-tune Stable Diffusion model for customized image generation.\n",
        "\n",
        "This Colab Notebook displays a programmatic approach for finetuning SDXL model for custom image generation and serving the finetuned model as an API using MonsterTuner.\n",
        "\n",
        "### To get started please sign up on [Monster API](https://monsterapi.ai/signup).\n",
        "\n",
        "#### For more info, you may explore our:\n",
        "1. [Developer Docs](https://developer.monsterapi.ai/docs/launch-an-sdxl-finetuning-job) on how to launch an SDXL Finetuning Job\n",
        "2. [Complete Guide](https://blog.monsterapi.ai/finetune-sdxl/) on Finetunng Stable Diffusion on your own images."
      ],
      "metadata": {
        "id": "PmcSfaD3uafX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monsterapi==1.0.8\n",
        "from IPython.display import HTML"
      ],
      "metadata": {
        "id": "sGMrkL2OsWRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy your Auth Key from [MonsterAPI Dashboard](https://monsterapi.ai/user/dashboard) and Paste it below:\n"
      ],
      "metadata": {
        "id": "YotYr5jOuy9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "import requests\n",
        "import json\n",
        "import mimetypes\n",
        "from monsterapi import client as mclient\n",
        "\n",
        "os.environ['MONSTER_API_KEY'] = 'PROVIDE_MONSTER_API_KEY'"
      ],
      "metadata": {
        "id": "1IO8sMJBs2Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload your Image Dataset as a ZIP File for SDXL Fine-tuning\n",
        "\n",
        "To fine-tune the SDXL model, start by uploading your image dataset, which should be compiled into a single ZIP file (with NO internal folders).\n",
        "\n",
        "Then we use `upload_file_to_api` function to push ZIP of images to MonsterAPI platform for using it at the time of fine-tuning."
      ],
      "metadata": {
        "id": "6Xa4kT6BfNaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_file_to_api(file_path):\n",
        "    url = \"https://api.monsterapi.ai/v1/upload\"\n",
        "    headers = {\n",
        "        \"accept\": \"application/json\",\n",
        "        \"authorization\": f\"Bearer {os.environ['MONSTER_API_KEY']}\"\n",
        "    }\n",
        "\n",
        "    file_name = os.path.basename(file_path)\n",
        "    # Get URLs for uploading\n",
        "    get_file_urls = requests.get(f\"{url}?filename={file_name}\", headers=headers)\n",
        "    response_json = json.loads(get_file_urls.text)\n",
        "    upload_url = response_json['upload_url']\n",
        "    download_url = response_json['download_url']\n",
        "\n",
        "    # Read file content as binary data\n",
        "    with open(file_path, 'rb') as file_data:\n",
        "        data = file_data.read()\n",
        "\n",
        "    # Upload file to S3\n",
        "    upload_headers = {\n",
        "        \"Content-Type\": mimetypes.guess_type(file_path)[0] or 'application/octet-stream',\n",
        "    }\n",
        "    response = requests.put(upload_url, data=data, headers=upload_headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(\"File uploaded successfully!\")\n",
        "        return download_url\n",
        "    else:\n",
        "        print(\"Failed to upload file\")\n",
        "        return None\n",
        "\n",
        "# Upload widget\n",
        "uploaded = files.upload()\n",
        "for file_name in uploaded.keys():\n",
        "    if file_name.endswith('.zip'):\n",
        "        file_path = '/content/' + file_name\n",
        "        download_url = upload_file_to_api(file_path)\n",
        "        if download_url:\n",
        "            print(f\"Download URL for {file_name}: {download_url}\")\n",
        "    else:\n",
        "        print(f\"Only ZIP files are allowed. The file '{file_name}' is not a ZIP file and will not be uploaded.\")"
      ],
      "metadata": {
        "id": "_Z7o_TYafFqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Launch Finetuning Job\n",
        "\n",
        "The `launch_payload` defines configurations for the model, including details like model name, image prompt, learning parameters, and data source settings.\n",
        "The model is fine-tuned using these settings, and upon completion, the session details, including a deployment ID, are printed."
      ],
      "metadata": {
        "id": "1eKU2vzhBmRc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIDefkKlq3ga"
      },
      "outputs": [],
      "source": [
        "client = mclient(api_key=os.environ.get(\"MONSTER_API_KEY\"))\n",
        "\n",
        "launch_payload = {\n",
        "    \"dreambooth_config\": {\n",
        "        \"model_name\": \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "        \"prompt\": \"Wolf in Full Moon Light\",\n",
        "        \"learning_rate\": 0.0001,\n",
        "        \"num_steps\": 500,\n",
        "        \"gradient_accumulation\": 4,\n",
        "        \"resolution\": 1024,\n",
        "        \"scheduler\": \"constant\"\n",
        "    },\n",
        "    \"huggingface_config\": { \"push_to_hub\": False },\n",
        "\n",
        "    \"dataset_config\": {\n",
        "    \"data_source_type\": \"s3_presigned_link\",\n",
        "    \"s3_presigned_url\": download_url\n",
        "  }\n",
        "}\n",
        "\n",
        "ret = client.finetune(service=\"text2image/sdxl-dreambooth\", params=launch_payload)\n",
        "deployment_id = ret.get(\"deployment_id\")\n",
        "print(ret)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch your Finetuning Status:\n",
        "\n",
        "Wait until the status is `Live`. It should take 5-10 minutes. You will get an email when the Status changes. You can also check the job progress in your MonsterAPI Dashboard"
      ],
      "metadata": {
        "id": "VTY5J2dDu90G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get deployment status\n",
        "status_ret = client.get_deployment_status(deployment_id)\n",
        "print(status_ret)"
      ],
      "metadata": {
        "id": "x_cYBrWFshFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n",
        "\n",
        "### Get Finetuning Job Logs\n",
        "\n",
        "To see your finetuning job progress, please run the cell below"
      ],
      "metadata": {
        "id": "faOSFTfwvp_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get deployment logs\n",
        "logs_ret = client.get_deployment_logs(deployment_id)\n",
        "print(logs_ret)"
      ],
      "metadata": {
        "id": "NB6nVxOxsiz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n",
        "\n",
        "### Terminate Finetuning Job\n",
        "\n",
        "CAUTION: If you wish to terminate your finetuning job, please uncomment and run the cell below"
      ],
      "metadata": {
        "id": "t87qbM5XvQHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Terminate Deployment\n",
        "# terminate_return = client.terminate_deployment(deployment_id)\n",
        "# print(terminate_return)"
      ],
      "metadata": {
        "id": "pjQqBOOGsj2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deploy your Finetuned SDXL Model\n",
        "\n",
        "You can deploy your Finetuned Model as a sharable Gradio UI in a single command once the Finetuning job is Completed"
      ],
      "metadata": {
        "id": "dMiY78bU8rGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "status_ret = client.get_deployment_status(deployment_id)\n",
        "loramodel_path = status_ret['info']['model_url']\n",
        "print(\"Model URL:\", loramodel_path)\n",
        "\n",
        "deployment_payload = {\n",
        "    \"deployment_name\": \"test_client_sdxl_dreambooth_deployment\",\n",
        "    \"basemodel_path\": \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    \"loramodel_path\": loramodel_path\n",
        "    }\n",
        "\n",
        "# Launch a deployment\n",
        "ret = client.deploy(\"sdxl-dreambooth\", deployment_payload)\n",
        "inference_deployment_id = ret.get(\"deployment_id\")\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "XxsCfPAT6k78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch your Deployment Status:\n",
        "\n",
        "Wait until the status is `Live`. It should take 5-10 minutes."
      ],
      "metadata": {
        "id": "FqgMXmFWBbgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get deployment status\n",
        "status_ret = client.get_deployment_status(inference_deployment_id)\n",
        "print(status_ret)"
      ],
      "metadata": {
        "id": "Qq1WAtyL8ZX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Play with your Finetuned Model\n",
        "\n",
        "---\n",
        "Once you have finetuned SDXL model, you can test it out and integrate it into your application by deploying it as an endpoint. To generate images with your finetuned image generation model, let us deploy the model with Gradio UI:\n"
      ],
      "metadata": {
        "id": "OMb_cVU7BBaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Gradio_URL = status_ret['URL']\n",
        "print(\"\\nMonsterAPI Gradio UI: \",Gradio_URL)\n",
        "HTML(f'<iframe src=\"{Gradio_URL}\" width=\"100%\" height=\"500px\"></iframe>')"
      ],
      "metadata": {
        "id": "-4gj-69t_cuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n",
        "\n",
        "### Get Deployment Job Logs\n",
        "\n",
        "To see your deployment job logs, please run the cell below"
      ],
      "metadata": {
        "id": "f05z6AFgBg2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get deployment logs\n",
        "logs_ret = client.get_deployment_logs(inference_deployment_id)\n",
        "print(logs_ret)"
      ],
      "metadata": {
        "id": "X1H8rkyy9OsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n",
        "\n",
        "### Terminate Deployment\n",
        "\n",
        "CAUTION: If you wish to terminate your live deployment, please uncomment and run the cell below"
      ],
      "metadata": {
        "id": "D34rHojRHpi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Terminate Deployment\n",
        "# terminate_return = client.terminate_deployment(deployment_id)\n",
        "# print(terminate_return)"
      ],
      "metadata": {
        "id": "StsmJaCNHuAZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}