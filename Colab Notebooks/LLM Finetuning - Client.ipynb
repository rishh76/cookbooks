{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Finetuning with MonsterTuner\n",
        "\n",
        "MonsterTuner is a new service from MonsterAPI designed to streamline the finetuning of popular AI models on our advanced compute infrastructure. With just one request, you can easily customize AI models for your business needs, making the process up to 10X more efficient and cost-effective.\n",
        "\n",
        "### Supported Models for Finetuning:\n",
        "\n",
        "1. LLM (Large Language Model) - For use-cases like chat completion, summary generation, sentiment analysis etc.\n",
        "2. Whisper - For speech to text transcription improvement.\n",
        "3. SDXL Dreambooth - Fine-tune Stable Diffusion model for customized image generation.\n",
        "\n",
        "\n",
        "Checkout our [Developer Docs](https://developer.monsterapi.ai/docs/launch-a-fine-tuning-job) on how to launch an LLM Finetuning Job with no-coding\n",
        "\n",
        "**How to finetune an LLM and Deploy it on MonsterAPI - [Complete Guide](https://blog.monsterapi.ai/how-to-fine-tune-a-large-language-model-llm-and-deploy-it-on-monsterapi/)**\n"
      ],
      "metadata": {
        "id": "IqENk2h8yZNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monsterapi==1.0.8"
      ],
      "metadata": {
        "id": "9JybrHe8y17T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sign up on [MonsterAPI](https://monsterapi.ai/signup?utm_source=llm-deploy-colab&utm_medium=referral) and get a free auth key. Paste it below:"
      ],
      "metadata": {
        "id": "ZK64gMDuy4KW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRowQKSnyC7-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from monsterapi import client as mclient\n",
        "\n",
        "os.environ['MONSTER_API_KEY'] = 'PROVIDE_YOUR_MONSTER_API_KEY'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Launch Finetuning Job\n",
        "\n",
        "This code block sets up `launch_payload` for fine-tuning an LLMs using specific configurations. The payload includes model path, LoRA parameters, data source details, and training settings such as learning rate and epochs. The model is fine-tuned using these settings"
      ],
      "metadata": {
        "id": "PxrorS9MKrCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = mclient(api_key=os.environ.get(\"MONSTER_API_KEY\"))\n",
        "\n",
        "launch_payload = {\n",
        "    \"pretrainedmodel_config\": {\n",
        "        \"model_path\": \"mistralai/Mistral-7B-v0.1\",\n",
        "        \"use_lora\": True,\n",
        "        \"lora_r\": 8,\n",
        "        \"lora_alpha\": 16,\n",
        "        \"lora_dropout\": 0,\n",
        "        \"lora_bias\": \"none\",\n",
        "        \"use_quantization\": False,\n",
        "        \"use_gradient_checkpointing\": False,\n",
        "        \"parallelization\": \"nmp\"\n",
        "    },\n",
        "    \"data_config\": {\n",
        "        \"data_path\": \"tatsu-lab/alpaca\",\n",
        "        \"data_subset\": \"default\",\n",
        "        \"data_source_type\": \"hub_link\",\n",
        "        \"prompt_template\": \"Here is an example on how to use tatsu-lab/alpaca dataset ### Input: {instruction} ### Output: {output}\",\n",
        "        \"cutoff_len\": 512,\n",
        "        \"prevalidated\": False\n",
        "    },\n",
        "    \"training_config\": {\n",
        "        \"early_stopping_patience\": 5,\n",
        "        \"num_train_epochs\": 1,\n",
        "        \"gradient_accumulation_steps\": 1,\n",
        "        \"warmup_steps\": 50,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"lr_scheduler_type\": \"reduce_lr_on_plateau\",\n",
        "        \"group_by_length\": False\n",
        "    },\n",
        "    \"logging_config\": { \"use_wandb\": False }\n",
        "}\n",
        "\n",
        "\n",
        "ret = client.finetune(service=\"llm\", params=launch_payload)\n",
        "deployment_id = ret.get(\"deployment_id\")\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "uaN93Po8y675"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch your Finetuning Job Status:\n",
        "\n",
        "Wait until the status is `Live`. It should take 5-10 minutes."
      ],
      "metadata": {
        "id": "4UEdXI-GzMgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get deployment status\n",
        "status_ret = client.get_deployment_status(deployment_id)\n",
        "print(status_ret)"
      ],
      "metadata": {
        "id": "NCIvdGfdzNCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n",
        "\n",
        "### Get Finetuning Job Logs\n",
        "\n",
        "To see your finetuning job progress, please run the cell below"
      ],
      "metadata": {
        "id": "k3qCzxOkzQ8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get deployment logs\n",
        "logs_ret = client.get_deployment_logs(deployment_id)\n",
        "print(logs_ret)"
      ],
      "metadata": {
        "id": "-oitFR1qzOhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n",
        "\n",
        "### Terminate Finetuning Job\n",
        "\n",
        "CAUTION: If you wish to terminate your finetuning job, please run the cell below"
      ],
      "metadata": {
        "id": "_TLZdFdazVER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Terminate Deployment\n",
        "# terminate_return = client.terminate_deployment(deployment_id)\n",
        "# print(terminate_return)"
      ],
      "metadata": {
        "id": "RDHWzEKkzTMY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}